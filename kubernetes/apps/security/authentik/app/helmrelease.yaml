---
# yaml-language-server: $schema=https://raw.githubusercontent.com/bjw-s/helm-charts/app-template-3.7.3/charts/other/app-template/schemas/helmrelease-helm-v2.schema.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: &app authentik
spec:
  interval: 30m
  chartRef:
    kind: OCIRepository
    name: app-template
  values:
    controllers:
      authentik:
        type: deployment
        replicas: 2
        strategy: RollingUpdate
        rollingUpdate:
          unavailable: "90%"
        annotations:
          reloader.stakater.com/auto: "true"
        pod:
          topologySpreadConstraints:
            - &tsc
              maxSkew: 1
              topologyKey: kubernetes.io/hostname
              whenUnsatisfiable: DoNotSchedule
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: *app
                  app.kubernetes.io/component: *app
        containers:
          main:
            image: &img
              repository: ghcr.io/goauthentik/server
              tag: 2025.2.4@sha256:36233579415aa2e2e52a6b0c45736cb871fe71460bfe0cf95d83f67528fb1182
            args: [server]
            env: &env
              TZ: America/New_York
              AUTHENTIK_POSTGRESQL__HOST:
                valueFrom:
                  secretKeyRef:
                    name: authentik-pg-app
                    key: host
              AUTHENTIK_POSTGRESQL__PORT:
                valueFrom:
                  secretKeyRef:
                    name: authentik-pg-app
                    key: port
              AUTHENTIK_POSTGRESQL__NAME:
                valueFrom:
                  secretKeyRef:
                    name: authentik-pg-app
                    key: dbname
              AUTHENTIK_POSTGRESQL__USER:
                valueFrom:
                  secretKeyRef:
                    name: authentik-pg-app
                    key: username
              AUTHENTIK_POSTGRESQL__PASSWORD:
                valueFrom:
                  secretKeyRef:
                    name: authentik-pg-app
                    key: password
              AUTHENTIK_POSTGRESQL__SSLMODE: verify-ca
              AUTHENTIK_POSTGRESQL__SSLROOTCERT: &pgca /secrets/pg/ca.crt
              AUTHENTIK_REDIS__HOST: redis.kinzoku.dev
              AUTHENTIK_SESSION_STORAGE: "db"
              AUTHENTIK_STORAGE__MEDIA__BACKEND: "s3"
              AUTHENTIK_STORAGE__MEDIA__S3__USE_SSL: "true"
              AUTHENTIK_STORAGE__MEDIA__S3__SECURE_URLS: "true"
              AUTHENTIK_LISTEN__TRUSTED_PROXY_CIDRS: "10.42.0.0/16"
              AUTHENTIK_OUTPUTS__DISCOVER: "false"
              AUTHENTIK_ERROR_REPORTING__ENABLED: "false"
              AUTHENTIK_ERROR_REPORTING__SEND_PII: "false"
            envFrom: &envFrom
              - secretRef:
                  name: authentik-secret
            securityContext: &sc
              readOnlyRootFilesystem: true
              allowPrivilegeEscalation: false
              capabilities:
                drop: [ALL]
            resources:
              requests:
                cpu: 30m
                memory: 600Mi
            ports:
              - name: http
                containerPort: &http 9000
              - name: https
                containerPort: &https 9443
              - name: metrics
                containerPort: &metrics 9300
            probes:
              liveness: &probe
                enabled: true
                type: HTTP
                port: http
                path: "/-/health/live/"
              readiness:
                enabled: true
                type: HTTP
                port: http
                path: "/-/health/ready/"
              startup:
                <<: *probe
                enabled: true
                spec: &startup
                  periodSeconds: 1
                  failureThreshold: 300
                  initialDelaySeconds: 15
          anubis:
            image:
              repository: ghcr.io/xe/x/anubis
              tag: latest@sha256:a7b24490df79512a18a198dc44cd3d8a4ac3389ec91866ec9720d6293c2bdde7
            env:
              TZ: "America/New_York"
              BIND: ":8923"
              DIFFICULTY: "5"
              SERVE_ROBOTS_TXT: "true"
              TARGET: "http://127.0.0.1:9000"
            securityContext: *sc
            resources:
              requests:
                cpu: 5m
                memory: 32Mi
            ports:
              - name: anubis
                containerPort: &anubis 8923
            probes:
              liveness:
                enabled: true
              readiness:
                enabled: true
      worker:
        type: deployment
        replicas: 2
        strategy: RollingUpdate
        rollingUpdate:
          unavailable: "90%"
        annotations:
          reloader.stakater.com/auto: "true"
        pod:
          topologySpreadConstraints:
            - <<: *tsc
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: *app
                  app.kubernetes.io/component: worker
        containers:
          main:
            image: *img
            args: [worker]
            env: *env
            envFrom: *envFrom
            securityContext: *sc
            resources:
              requests:
                cpu: 20m
                memory: 512Mi
            probes:
              liveness: &worker-probe
                enabled: true
                custom: true
                spec: &wps
                  exec:
                    command: ["ak", "healthcheck"]
              readiness: *worker-probe
              startup:
                <<: *worker-probe
                spec:
                  <<: [*startup, *wps]
      ldap:
        type: deployment
        replicas: 2
        strategy: RollingUpdate
        rollingUpdate:
          unavailable: "90%"
        pod:
          topologySpreadConstraints:
            - <<: *tsc
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: *app
                  app.kubernetes.io/component: ldap
        containers:
          main:
            image:
              <<: *img
              repository: ghcr.io/goauthentik/ldap
              tag: 2025.2.4@sha256:cc98bc43e3713095097ae322df1ebd3b0ae76ecd0bd67ae7cd1e0375cce51b1b
            env:
              AUTHENTIK_HOST: "https://auth.kinzoku.dev"
              AUTHENTIK_INSECURE: "true"
              AUTHENTIK_TOKEN:
                valueFrom:
                  secretKeyRef:
                    name: authentik-tokens-secret
                    key: AUTHENTIK_TOKEN_LDAP
            securityContext: *sc
            resources:
              requests:
                cpu: 10m
                memory: 128Mi
            probes:
              liveness: &ldap-probe
                enabled: true
                custom: true
                spec: &lps
                  exec:
                    command: ["/ldap", "healthcheck"]
              readiness: *ldap-probe
              startup:
                <<: *ldap-probe
                spec:
                  <<: [*startup, *lps]
      proxy:
        type: deployment
        replicas: 2
        strategy: RollingUpdate
        rollingUpdate:
          unavailable: "90%"
        pod:
          topologySpreadConstraints:
            - <<: *tsc
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: *app
                  app.kubernetes.io/component: proxy
        containers:
          main:
            image:
              <<: *img
              repository: ghcr.io/goauthentik/proxy
              tag: 2025.2.4@sha256:4de697fbeae74a65526fc1fe4ec9770ebc38d02c7e863c7b0ecb8975003a70d3
            env:
              AUTHENTIK_HOST: "https://auth.kinzoku.dev"
              AUTHENTIK_INSECURE: "true"
              AUTHENTIK_TOKEN:
                valueFrom:
                  secretKeyRef:
                    name: authentik-tokens-secret
                    key: AUTHENTIK_TOKEN_PROXY
            securityContext: *sc
            resources:
              requests:
                cpu: 10m
                memory: 128Mi
            probes:
              liveness: &proxy-probe
                enabled: true
                custom: true
                spec: &pps
                  exec:
                    command: ["/proxy", "healthcheck"]
              readiness: *proxy-probe
              startup:
                <<: *proxy-probe
                spec:
                  <<: [*startup, *pps]
    service:
      authentik:
        controller: authentik
        ports:
          http: &port
            port: *http
            protocol: HTTP
            appProtocol: http
          http-80:
            <<: *port
            port: 80
            targetPort: *http
          metrics:
            <<: *port
            port: *metrics
          anubis:
            <<: *port
            port: *anubis
      expose:
        primary: false
        controller: authentik
        type: LoadBalancer
        annotations:
          io.cilium/internal: "true"
          io.cilium/lb-ipam-ips: "192.168.40.16"
        ports:
          http:
            port: 443
            targetPort: *https
            protocol: HTTPS
            appProtocol: https
      ldap:
        primary: false
        controller: ldap
        type: LoadBalancer
        annotations:
          io.cilium/lb-ipam-ips: "192.168.40.13"
        ports:
          ldap-tcp: &ldap
            port: 389
            targetPort: 3389
            protocol: TCP
            appProtocol: ldap
          ldap-udp:
            <<: *ldap
            protocol: UDP
          ldaps-tcp: &ldaps
            port: 636
            targetPort: 6636
            protocol: TCP
            appProtocol: ldaps
          ldaps-udp:
            <<: *ldaps
            protocol: UDP
      proxy:
        primary: false
        controller: proxy
        type: LoadBalancer
        annotations:
          io.cilium/lb-ipam-ips: "192.168.40.14"
        ports:
          proxy-http-tcp: &proxy
            port: 9000
            targetPort: 9000
            protocol: TCP
            appProtocol: http
          proxy-http-udp:
            <<: *proxy
            protocol: UDP
          proxy-https-tcp: &proxy-https
            port: 9443
            targetPort: 9443
            protocol: TCP
            appProtocol: https
          proxy-https-udp:
            <<: *proxy-https
            protocol: UDP
    ingress:
      external: &ingress
        className: external
        annotations:
          external-dns.alpha.kubernetes.io/target: external.kinzoku.dev
        hosts:
          - host: &host auth.kinzoku.dev
            paths:
              - &path
                path: /
                pathType: Prefix
                service:
                  identifier: authentik
                  port: http
        tls: &tls
          - hosts: [*host]
            secretName: authentik-tls
    persistence:
      pg-ca:
        type: secret
        name: authentik-pg-ca
        defaultMode: 0400
        globalMounts:
          - subPath: ca.crt
            path: *pgca
      tls:
        type: secret
        name: authentik-tls
        defaultMode: 0400
        globalMounts:
          - path: "/certs/auth.kinzoku.dev-k8s"
      tmp:
        type: emptyDir
        medium: Memory
        globalMounts:
          - path: "/media/public"
    defaultPodOptions:
      automountServiceAccountToken: false
      enableServiceLinks: false
      hostAliases:
        - ip: "192.168.40.16"
          hostnames: ["auth.kinzoku.dev"]
      securityContext:
        runAsNonRoot: true
        runAsUser: &uid 1000
        runAsGroup: *uid
        fsGroup: *uid
        fsGroupChangePolicy: Always
        seccompProfile: { type: RuntimeDefault }
    serviceMonitor:
      authentik:
        serviceName: authentik
        endpoints:
          - port: metrics
            scheme: http
            path: /metrics
            interval: 1m
            scrapeTimeout: 30s
